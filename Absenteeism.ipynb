{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Absenteeism Preporocessing and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_csv_data= pd.read_csv('Absenteeism_data.csv')\n",
    "df= raw_csv_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['ID'], axis= 1)\n",
    "reason_columns= pd.get_dummies(df['Reason for Absence'])\n",
    "df= df.drop(['Reason for Absence'], axis=1)\n",
    "\n",
    "reason_type_1= reason_columns.loc[:, 1:14].max(axis=1)\n",
    "reason_type_2= reason_columns.loc[:, 15:17].max(axis=1)\n",
    "reason_type_3= reason_columns.loc[:, 18:21].max(axis=1)\n",
    "reason_type_4= reason_columns.loc[:, 22:28].max(axis=1)\n",
    "\n",
    "df= pd.concat([df, reason_type_1, reason_type_2, reason_type_3, reason_type_4], axis= 1)\n",
    "\n",
    "columns_names= ['Date', 'Transportation Expense', 'Distance to Work', 'Age',\n",
    "       'Daily Work Load Average', 'Body Mass Index', 'Education',\n",
    "       'Children', 'Pets', 'Absenteeism Time in Hours', 'Reason_1', 'Reason_2', 'Reason_3', 'Reason_4']\n",
    "\n",
    "df.columns= columns_names\n",
    "\n",
    "columns_names_orders= ['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4', 'Date', 'Transportation Expense', 'Distance to Work', 'Age',\n",
    "       'Daily Work Load Average', 'Body Mass Index', 'Education',\n",
    "       'Children', 'Pets', 'Absenteeism Time in Hours']\n",
    "\n",
    "df= df[columns_names_orders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reason_mod= df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_reason_mod['Date'][0])\n",
    "\n",
    "df_reason_mod['Date']=pd.to_datetime(df_reason_mod['Date'], format= '%d/%m/%Y')\n",
    "\n",
    "list_months=[]\n",
    "for i in range(len(df_reason_mod['Date'])):\n",
    "               list_months.append(df_reason_mod['Date'][i].month)\n",
    "        \n",
    "df['Month Values']= list_months\n",
    "\n",
    "df_reason_mod['Date'][0].weekday()\n",
    "\n",
    "def date_to_week(date_value):\n",
    "    return date_value.weekday()\n",
    "df_reason_mod['Day of the Week']= df_reason_mod['Date'].apply(date_to_week)\n",
    "\n",
    "df_reason_mod['Education'].unique()\n",
    "df_reason_mod['Education'].value_counts()\n",
    "# 1: High school, 2: Graduate, 3: Postgraduate, 4: Master or Doctor\n",
    "\n",
    "map = {1: 0, 2: 1, 3: 1, 4:1}\n",
    "df_reason_mod['Education']= df_reason_mod['Education'].map(map)\n",
    "\n",
    "df_reason_mod= df_reason_mod.drop(['Date'], axis=1)\n",
    "\n",
    "df_reason_mod['Month Values']= df['Month Values']\n",
    "\n",
    "df_reason_mod.columns.values\n",
    "\n",
    "columns=['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4',\n",
    "       'Month Values', 'Day of the Week', 'Transportation Expense', 'Distance to Work', 'Age',\n",
    "       'Daily Work Load Average', 'Body Mass Index', 'Education',\n",
    "       'Children', 'Pets', 'Absenteeism Time in Hours'\n",
    "       ]\n",
    "\n",
    "df_reason_mod= df_reason_mod[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "\n",
    "data_preprocessed= df_reason_mod.copy()\n",
    "\n",
    "# data_preprocessed.to_excel('Abseteeism_preprocessed.xlsx')\n",
    "# data_preprocessed= pd.read_csv('Abseteeism_preprocessed.csv')\n",
    "# data_preprocessed= data_preprocessed.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "median= data_preprocessed['Absenteeism Time in Hours'].median()\n",
    "targets= np.where(data_preprocessed['Absenteeism Time in Hours']>median, 1, 0)\n",
    "\n",
    "targets.sum()/targets.shape[0]   # A balance of targets is essential for targets, 45%-55% for targets is always sufficient\n",
    "\n",
    "data_with_targets= data_preprocessed.drop(['Absenteeism Time in Hours'], axis=1)\n",
    "\n",
    "unscaled_inputs= data_with_targets.iloc[:, :14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class CustomScaler(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, columns, copy= True, with_maen= True, with_std= True):\n",
    "        self.scaler= StandardScaler()\n",
    "        self.columns= columns\n",
    "        self.mean= None\n",
    "        self.var= None\n",
    "        \n",
    "    def fit(self, X, y= None):\n",
    "        self.scaler.fit(X[self.columns], y)\n",
    "        self.mean = np.mean(X[self.columns])\n",
    "        self.var= np.var(X[self.columns])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y= None):\n",
    "        init_col_order= X.columns\n",
    "        X_scaled= pd.DataFrame(self.scaler.transform(X[self.columns]), columns= self.columns)\n",
    "        X_not_scaled= X.loc[:, ~X.columns.isin(self.columns)]\n",
    "        return pd.concat([X_not_scaled, X_scaled], axis=1)[init_col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_omit= ['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4', 'Education']\n",
    "columns_to_scale= [x for x in unscaled_inputs.columns.values if x not in columns_to_omit]\n",
    "\n",
    "absenteeism_scaler= CustomScaler(columns_to_scale)\n",
    "absenteeism_scaler.fit(unscaled_inputs)\n",
    "scaled_inputs = absenteeism_scaler.transform(unscaled_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train & test and shuffle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(scaled_inputs, targets, train_size= 0.8, shuffle= True, random_state= 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model, Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg= LogisticRegression()\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7678571428571429"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7678571428571429"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs=reg.predict(x_train)\n",
    "\n",
    "np.sum(model_outputs == y_train)/ model_outputs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the intercept and coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.97766912] [[ 2.92224312  1.66511081  1.66511081  1.2255857   0.11528594 -0.20847351\n",
      "   0.78472433 -0.07390694 -0.27591319  0.05386436  0.32688999  0.18619675\n",
      "   0.46380254 -0.35843023]]\n"
     ]
    }
   ],
   "source": [
    "print(reg.intercept_, reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name= unscaled_inputs.columns.values\n",
    "\n",
    "summary_table=pd.DataFrame(columns= ['Features'], data= feature_name)\n",
    "summary_table['Coefficients']= np.transpose(reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_table.index= summary_table.index + 1\n",
    "summary_table.loc[0]= ['Intercept', reg.intercept_[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients</th>\n",
       "      <th>Odds_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reason_1</td>\n",
       "      <td>2.922243</td>\n",
       "      <td>18.582924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reason_2</td>\n",
       "      <td>1.665111</td>\n",
       "      <td>5.286259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reason_3</td>\n",
       "      <td>1.665111</td>\n",
       "      <td>5.286259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reason_4</td>\n",
       "      <td>1.225586</td>\n",
       "      <td>3.406160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transportation Expense</td>\n",
       "      <td>0.784724</td>\n",
       "      <td>2.191803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Children</td>\n",
       "      <td>0.463803</td>\n",
       "      <td>1.590109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Body Mass Index</td>\n",
       "      <td>0.326890</td>\n",
       "      <td>1.386649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Education</td>\n",
       "      <td>0.186197</td>\n",
       "      <td>1.204659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Month Values</td>\n",
       "      <td>0.115286</td>\n",
       "      <td>1.122194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Daily Work Load Average</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>1.055341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Distance to Work</td>\n",
       "      <td>-0.073907</td>\n",
       "      <td>0.928758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Day of the Week</td>\n",
       "      <td>-0.208474</td>\n",
       "      <td>0.811823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.275913</td>\n",
       "      <td>0.758879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pets</td>\n",
       "      <td>-0.358430</td>\n",
       "      <td>0.698772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-1.977669</td>\n",
       "      <td>0.138391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Features  Coefficients  Odds_ratio\n",
       "1                  Reason_1      2.922243   18.582924\n",
       "2                  Reason_2      1.665111    5.286259\n",
       "3                  Reason_3      1.665111    5.286259\n",
       "4                  Reason_4      1.225586    3.406160\n",
       "7    Transportation Expense      0.784724    2.191803\n",
       "13                 Children      0.463803    1.590109\n",
       "11          Body Mass Index      0.326890    1.386649\n",
       "12                Education      0.186197    1.204659\n",
       "5              Month Values      0.115286    1.122194\n",
       "10  Daily Work Load Average      0.053864    1.055341\n",
       "8          Distance to Work     -0.073907    0.928758\n",
       "6           Day of the Week     -0.208474    0.811823\n",
       "9                       Age     -0.275913    0.758879\n",
       "14                     Pets     -0.358430    0.698772\n",
       "0                 Intercept     -1.977669    0.138391"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table= summary_table.sort_index()\n",
    "summary_table['Odds_ratio']= np.exp(summary_table.Coefficients)\n",
    "summary_table.sort_values('Odds_ratio', ascending= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_proba= reg.predict_proba(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
